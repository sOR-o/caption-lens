{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832878e3-f252-453c-b1e3-039cd5fef164",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops -qq\n",
    "!pip install tensorflow_datasets -qq\n",
    "!pip install tensorflow-text -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73001b7-0587-416b-882c-34e4291947c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "import collections\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "import einops\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e84b04-d1cc-4adf-9106-0ccc411c3f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/saurabh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f857d10-6162-4c85-bf22-3b7465bd12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path='../dataset/flickr8k'):\n",
    "    \"\"\"\n",
    "    Downloads and extracts the Flickr8k dataset and text files.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path where the dataset will be stored.\n",
    "    \"\"\"\n",
    "    path = pathlib.Path(path)\n",
    "    \n",
    "    # Download and extract the Flickr8k Dataset\n",
    "    tf.keras.utils.get_file(\n",
    "        origin='https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip',\n",
    "        cache_dir='.',\n",
    "        cache_subdir=path,\n",
    "        extract=True\n",
    "    )\n",
    "    \n",
    "    # Download and extract the Flickr8k text files\n",
    "    tf.keras.utils.get_file(\n",
    "        origin='https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip',\n",
    "        cache_dir='.',\n",
    "        cache_subdir=path,\n",
    "        extract=True\n",
    "    )\n",
    "\n",
    "def get_dataset(path='../dataset/flickr8k/Flickr8k_text.zip'):\n",
    "    \"\"\"\n",
    "    Reads and processes the Flickr8k dataset to create training and testing datasets.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path where the dataset is stored.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of training and testing datasets.\n",
    "    \"\"\"\n",
    "    path = pathlib.Path(path)\n",
    "    \n",
    "    # Read and process captions\n",
    "    captions = (path / 'Flickr8k.token.txt').read_text().splitlines()\n",
    "    captions = [cap.split('\\t') for cap in captions]\n",
    "    captions = [(img_path.split('#')[0], cap) for (img_path, cap) in captions]\n",
    "    \n",
    "    # Create a dictionary of image paths and their respective captions\n",
    "    cap_dict = collections.defaultdict(list)\n",
    "    for img_path, cap in captions:\n",
    "        cap_dict[img_path].append(cap)\n",
    "    \n",
    "    # Read training and testing image paths\n",
    "    train_imgs_path = (path / 'Flickr_8k.trainImages.txt').read_text().splitlines()\n",
    "    test_imgs_path = (path / 'Flickr_8k.testImages.txt').read_text().splitlines()\n",
    "    \n",
    "    # Create training and testing datasets\n",
    "    train_caps = [\n",
    "        (str(path / 'Flicker8k_Dataset' / img_path), cap_dict[img_path]) \n",
    "        for img_path in train_imgs_path\n",
    "    ]\n",
    "    test_caps = [\n",
    "        (str(path / 'Flicker8k_Dataset' / img_path), cap_dict[img_path]) \n",
    "        for img_path in test_imgs_path\n",
    "    ]\n",
    "    \n",
    "    # Convert to TensorFlow datasets\n",
    "    train_raw = tf.data.experimental.from_list(train_caps)\n",
    "    test_raw = tf.data.experimental.from_list(test_caps)\n",
    "\n",
    "    return train_raw, test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0554458f-9974-424f-b364-53fd3b3230be",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data()\n",
    "train_raw, test_raw = get_dataset() # Use path='flickr8k' if on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1725ceb-26a0-4546-9a55-2dcb90529298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 1000\n",
      "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.string, name=None))\n",
      "tf.Tensor(b'../dataset/flickr8k/Flickr8k_text.zip/Flicker8k_Dataset/2513260012_03d33305cf.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'A black dog is running after a white dog in the snow .'\n",
      " b'Black dog chasing brown dog through snow'\n",
      " b'Two dogs chase each other across the snowy ground .'\n",
      " b'Two dogs play together in the snow .'\n",
      " b'Two dogs running through a low lying body of water .'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_raw), len(test_raw))\n",
    "print(train_raw.element_spec)\n",
    "\n",
    "for img_path, captions in train_raw.take(1):\n",
    "    break\n",
    "\n",
    "print(img_path)\n",
    "print(captions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
